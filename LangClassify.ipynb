{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import itertools\n",
    "import pytesseract\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wand.image import Image\n",
    "from wand.color import Color\n",
    "import re\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import sys\n",
    "from statistics import mode\n",
    "import operator\n",
    "if sys.version_info[0] < 3:\n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "from pyfasttext import FastText\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from extract import getModeSplits, mode\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "model = FastText('/corpora/LORELEI/fastText/lid.176.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('en', 0.6931304869158441),\n",
       " ('de', 0.04898541251556121),\n",
       " ('es', 0.026136760232436676),\n",
       " ('pt', 0.022172690190369555),\n",
       " ('fr', 0.013090189787923609),\n",
       " ('ru', 0.012807392024569316),\n",
       " ('cs', 0.012650313032261632),\n",
       " ('it', 0.011847595759225608),\n",
       " ('he', 0.008193057293154825),\n",
       " ('fa', 0.007267200646247198)]"
      ]
     },
     "execution_count": 1312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba_single('Green', k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Mende/pickles/MendeManual-67.pkl', 'rb') as pickle_file:\n",
    "    content = pickle.load(pickle_file)\n",
    "with open('Mende/pickles/MendeManual-67_modedict.pkl', 'rb') as pickle_file_mode:\n",
    "    modedict = pickle.load(pickle_file_mode)\n",
    "with open('Mende/pickles/MendeManual-67_pd_hocr.pkl', 'rb') as pickle_file_mode:\n",
    "    hocr = pickle.load(pickle_file_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[2, ['Bi nja we leila plo', 'Did you make drainages in~-be']],\n",
       "  [2, ['tisiea ti luahun', 'tween the plots']]],\n",
       " 1: [[1, ['Sia le ge bi hun- Yes, just as you instructed me']],\n",
       "  [2, ['gei ia a nge', 'the last time']],\n",
       "  [2, ['Ke nya sina wama ngi', \"Then E'll be coming tomorrow to\"]]],\n",
       " 2: [[1, ['kpeteihun lo. Biya see the swamp. When trans']],\n",
       "  [2, ['mbei hinma, ba ti', 'planting the rice, do not']],\n",
       "  [1, ['lootoo waa gblagblaga cluster them together']],\n",
       "  [2, ['bia vul lo sina', \"<I suppose you'll be coming\"]],\n",
       "  [2, ['wa. ma bi na Ilo', 'tomorrow to see there your']]],\n",
       " 4: [[2, ['Ke ba nya malelo', 'Then you will meet me']],\n",
       "  [2, ['Mua lo', 'We shall see']]],\n",
       " 5: [[1, ['Glossary of Tools/Useful Expressions on Farming']],\n",
       "  [2, ['Benbei', 'Fishing net']],\n",
       "  [2, ['Bumbui', 'Fishing Trap']],\n",
       "  [2, ['Due', 'Brush']],\n",
       "  [2, ['Due kpe', 'Brushing time']],\n",
       "  [2, ['Felei', 'Winnowing time']],\n",
       "  [2, ['Gaaga kpe', 'Time for clearing after burning']],\n",
       "  [2, ['Hambui', 'An object made of wire hung over']]],\n",
       " 6: [[1, ['fire for drying fish or meat']],\n",
       "  [2, ['Kali', 'Hoe']],\n",
       "  [2, ['Kondei', 'Mortar']],\n",
       "  [2, ['Koni', 'Axe']],\n",
       "  [2, ['Kobot', 'Mat (made out cf bamboo']],\n",
       "  [2, ['Kpakai', 'Three legged wooden chair']],\n",
       "  [2, ['typical of Mendes', 'used']]],\n",
       " 7: [[1, ['especially an farms']],\n",
       "  [2, ['Kpasei', 'Circular object used for']],\n",
       "  [1, ['climbing palm trees']],\n",
       "  [2, ['Kpangbei', 'Broom']],\n",
       "  [2, ['Kpawei', 'Forked stick']],\n",
       "  [2, ['Kpuloi', 'Gourd/keg']],\n",
       "  [2, ['Kpoe', 'Farm house']],\n",
       "  [2, ['Lavulei', 'Sling used for scaring birds']],\n",
       "  [2, ['Mbahul', 'Seed rice']],\n",
       "  [2, ['Mbowei', 'Knife']],\n",
       "  [2, ['Mbale bowei', 'Sickle/knife used for cutting']]],\n",
       " 8: [[1, ['rice']],\n",
       "  [2, ['Ndoe bowel', 'Brushing knife']],\n",
       "  [2, ['Mbogbeili', 'Cutlass']],\n",
       "  [2, ['Ps bogbel', 'Cutlass for cutting down trees']],\n",
       "  [2, ['Ndogboi', 'Bush']],\n",
       "  [2, ['Ndoli', 'Hook']],\n",
       "  [2, ['Ngombui', 'Fire']],\n",
       "  [2, ['Piyei', 'Container for putting']]],\n",
       " 10: [[2, ['Hosted for free on livelingua.com', 'â€˜']]]}"
      ]
     },
     "execution_count": 1272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster1d(x):\n",
    "    X = np.array(list(zip(x, np.zeros(len(x)))), dtype=np.float32)\n",
    "    bandwidth = estimate_bandwidth(X, quantile=0.03)\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(X)\n",
    "    labels = ms.labels_\n",
    "    labels_unique = np.unique(labels)\n",
    "    n_clusters_ = len(labels_unique)\n",
    "    cluster_centers = np.argsort(ms.cluster_centers_[:,0])\n",
    "\n",
    "    newlabelindex = {}\n",
    "    for index, index2 in zip(list(labels_unique), list(cluster_centers)):\n",
    "        newlabelindex[index] = index2\n",
    "    \n",
    "    lookup = {}\n",
    "    line2members = OrderedDict()\n",
    "    members2line = OrderedDict()\n",
    "    lookup_val = {}\n",
    "    for k in range(n_clusters_):\n",
    "        my_members = labels == newlabelindex[k]\n",
    "        #print(\"cluster {0}: {1}\".format(k, X[my_members, 0]))\n",
    "        members = [x for x in hocr.loc[my_members, \"text\"]]\n",
    "        #print(members)\n",
    "        #print('')\n",
    "        line2members[k] = members\n",
    "        lookup[k] = my_members\n",
    "        lookup_val[k] = X[my_members, 0]\n",
    "        joined = \" \".join([x for x in members if isinstance(x, str)])\n",
    "        members2line[joined] = k\n",
    "    \n",
    "    return lookup, line2members, members2line, lookup_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_lookup, line2members, members2line, l_lookup_val = cluster1d(hocr[\"top\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c_lookup, col2members, members2col, c_lookup_val = cluster1d(hocr[\"left\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_Hocr_Line(data, linedict):\n",
    "    new_line2members = {}\n",
    "    for para in data:\n",
    "        for line in data[para]:\n",
    "            tokens = \" \".join(line[1]).split()\n",
    "            scores = {}\n",
    "            for line_hocr in linedict:\n",
    "                tot = 0\n",
    "                match = 0\n",
    "                for tok in tokens:\n",
    "                    if tok in linedict[line_hocr]:\n",
    "                        match += 1\n",
    "                    tot += 1\n",
    "                scores[line_hocr] = match/tot\n",
    "            max_line_num = max(scores.items(), key=operator.itemgetter(1))[0]\n",
    "            line.append(max_line_num)\n",
    "            new_line2members[max_line_num] = line[1]\n",
    "    return new_line2members\n",
    "\n",
    "line2members = assign_Hocr_Line(content, line2members)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>par_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word_num</th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1516</td>\n",
       "      <td>909</td>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1516</td>\n",
       "      <td>909</td>\n",
       "      <td>136</td>\n",
       "      <td>54</td>\n",
       "      <td>95</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level  page_num  block_num  par_num  line_num  word_num  left  top  \\\n",
       "109      4         1          1        1        11         0  1516  909   \n",
       "110      5         1          1        1        11         1  1516  909   \n",
       "\n",
       "     width  height  conf  text  \n",
       "109    136      54    -1   NaN  \n",
       "110    136      54    95  self  "
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hocr.iloc[l_lookup[10],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wLeft(word, line):\n",
    "    sample = hocr.iloc[l_lookup[line],:]\n",
    "    indices = sample.index[sample['text'].str.contains(word, na=False)].tolist()\n",
    "    w_Left = hocr[\"left\"].iloc[indices[0]]\n",
    "    return w_Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_column(string):\n",
    "    for members in members2line:\n",
    "        if string in members:\n",
    "            line = int(members2line[members])\n",
    "            prevline = line - 1\n",
    "    w_Left = get_wLeft(string, line)\n",
    "    prev_line_sample = hocr.iloc[lookup[prevline]]\n",
    "    prev_line_sample_filtered = prev_line_sample.iloc[pd.Index(prev_line_sample[\"text\"]).notnull()]\n",
    "    #print(prev_line_sample_filtered)\n",
    "    returned_word_index = prev_line_sample_filtered.iloc[(prev_line_sample_filtered['left']-w_Left).abs().argsort()[:1]]\n",
    "    returned_word = returned_word_index.iloc[0][\"text\"]\n",
    "    return returned_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchCol(pixel_num, col_cluster_dict):\n",
    "    for i in col_cluster_dict:\n",
    "        if pixel_num in col_cluster_dict[i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineCols(line):\n",
    "    word_to_column = {}\n",
    "    members = line2members[line]\n",
    "    col_list = []\n",
    "    for member in members:\n",
    "        try:\n",
    "            memb = member.split()[0]\n",
    "        except:\n",
    "            pass\n",
    "        left = get_wLeft(memb, line)\n",
    "        col = matchCol(left, c_lookup_val)\n",
    "        col_list.append(col)\n",
    "    return col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binCols(list_of_col_idxs):\n",
    "    new = []\n",
    "    already_added = set()\n",
    "    for idx, item in enumerate(list_of_col_idxs):\n",
    "        forward_match = False\n",
    "        if idx < len(list_of_col_idxs)-1:\n",
    "            forward_match = list_of_col_idxs[idx+1] == item + 1\n",
    "        if forward_match:\n",
    "            new.append([item, list_of_col_idxs[idx+1]])\n",
    "            already_added.add(item)\n",
    "            already_added.add(list_of_col_idxs[idx+1])\n",
    "        else:\n",
    "            if item not in already_added:\n",
    "                new.append([item])\n",
    "                already_added.add(item)\n",
    "    colOrg = OrderedDict()\n",
    "    table = int()\n",
    "    for i, col_num in enumerate(new):\n",
    "        x = i+1\n",
    "        if x % 2 == 0:\n",
    "            table += 1\n",
    "            colOrg[table] = [new[i-1], col_num]\n",
    "    print(new)\n",
    "    return colOrg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareAgainstMode(data):\n",
    "    replacements = []\n",
    "    deletions = []\n",
    "    previous_para_id = data\n",
    "    collapse_marker = False\n",
    "    candidate_lines = []\n",
    "    for i in data:\n",
    "        for line_idx, c in enumerate(data[i]):\n",
    "            abs_line_num = c[2]\n",
    "            if c[0] != modedict[i] or c[0] % 2 != 0:\n",
    "                candidate_lines.append(abs_line_num)\n",
    "                line = c\n",
    "                c_para = int()\n",
    "                index_in_para = int()\n",
    "                if line_idx != 0:\n",
    "                    line_membs_cols = determineCols(data[i][line_idx][2])\n",
    "                    prev_line_num = data[i][line_idx-1][2]\n",
    "                    p_line = data[i][line_idx-1]\n",
    "                    p_line_membs_cols = determineCols(prev_line_num)\n",
    "                    index_in_para = line_idx-1\n",
    "                    c_para = i\n",
    "                else:\n",
    "                    line_membs_cols = determineCols(data[i][line_idx][2])\n",
    "                    prev_line_num = data[previous_para_id][-1][2]\n",
    "                    if prev_line_num == abs_line_num - 1:\n",
    "                        p_line = data[previous_para_id][-1]\n",
    "                        p_line_membs_cols = determineCols(prev_line_num)\n",
    "                        index_in_para = -1\n",
    "                        c_para = previous_para_id\n",
    "                uniques = sorted(set(line_membs_cols + p_line_membs_cols))\n",
    "                col_bins = binCols(uniques)                    \n",
    "                culprit_tables = {}\n",
    "                for table in col_bins:\n",
    "                    for idx, col in enumerate(col_bins[table]):\n",
    "                        if not any(item in line_membs_cols for item in col):\n",
    "                            culprit_tables.setdefault(table, [])\n",
    "                            culprit_tables[table].append(idx-1)\n",
    "                culprit_idxs = []\n",
    "                for culprit in culprit_tables:\n",
    "                    try:\n",
    "                        bad_columns = culprit_tables[culprit][0]\n",
    "                        for index, x in enumerate(line_membs_cols):\n",
    "                            if x in col_bins[culprit][bad_columns]:\n",
    "                                culprit_idxs.append((index, col_bins[culprit][bad_columns], culprit_tables[culprit][0]))\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                if len(culprit_idxs) > 0:\n",
    "                    for y in culprit_idxs:\n",
    "                        for prev_idx, q in enumerate(p_line_membs_cols):\n",
    "                            if q in y[1]:\n",
    "                                prev_bad_abs = prev_idx\n",
    "                        try:\n",
    "                            replacement_phrase = p_line[1][prev_bad_abs] + ' ' + line[1][y[0]]\n",
    "                            replacements.append((c_para, index_in_para, prev_bad_abs, replacement_phrase))\n",
    "                            deletions.append((i, line_idx, y[0]))\n",
    "                        except Exception as e:\n",
    "                            print(\"replacement index error\")\n",
    "\n",
    "        previous_para_id = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1303-d0e98ac0f6df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompareAgainstMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1302-fc39344c7e12>\u001b[0m in \u001b[0;36mcompareAgainstMode\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mc_para\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0mline_membs_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermineCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                     \u001b[0mprev_line_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprevious_para_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mprev_line_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mabs_line_num\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1300-3b6176ddc33a>\u001b[0m in \u001b[0;36mdetermineCols\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetermineCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mword_to_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline2members\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcol_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmember\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 7"
     ]
    }
   ],
   "source": [
    "compareAgainstMode(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[2,\n",
       "   ['Bi nja we leila plo tisiea ti luahun',\n",
       "    'Did you make drainages in~-be tween the plots'],\n",
       "   1,\n",
       "   1]],\n",
       " 1: [[2,\n",
       "   ['Ke nya sina wama ngi mbei hinma, ba ti',\n",
       "    \"Then E'll be coming tomorrow to kpeteihun lo. Biya see the swamp. When trans planting the rice, do not lootoo waa gblagblaga cluster them together\"],\n",
       "   5,\n",
       "   1]],\n",
       " 2: [[1,\n",
       "   ['lootoo waa gblagblaga cluster them together wa. ma bi na Ilo'],\n",
       "   7,\n",
       "   1]],\n",
       " 4: [[2, ['Ke ba nya malelo', 'Then you will meet me'], 12, 1],\n",
       "  [2, ['Mua lo', 'We shall see'], 13, 1]],\n",
       " 5: [[2, ['Benbei', 'Fishing net'], 15, 15],\n",
       "  [2, ['Bumbui', 'Fishing Trap'], 16, 16],\n",
       "  [2, ['Due', 'Brush'], 17, 17],\n",
       "  [2, ['Due kpe', 'Brushing time'], 18, 17],\n",
       "  [2, ['Felei', 'Winnowing time'], 19, 19],\n",
       "  [2, ['Gaaga kpe', 'Time for clearing after burning'], 20, 1],\n",
       "  [2, ['Hambui', 'An object made of wire hung over'], 21, 21]],\n",
       " 6: [[1, ['fire for drying fish or meat'], 22, 1],\n",
       "  [2, ['Kali', 'Hoe'], 22, 22],\n",
       "  [2, ['Kondei', 'Mortar'], 23, 23],\n",
       "  [2, ['Koni', 'Axe'], 24, 24],\n",
       "  [2, ['Kobot', 'Mat (made out cf bamboo'], 25, 25],\n",
       "  [2,\n",
       "   ['Kpakai typical of Mendes especially an farms',\n",
       "    'Three legged wooden chair used especially an farms'],\n",
       "   26,\n",
       "   1]],\n",
       " 7: [[1, ['climbing palm trees'], 30, 1],\n",
       "  [2, ['Kpangbei', 'Broom'], 31, 31],\n",
       "  [2, ['Kpuloi', 'Gourd/keg'], 33, 33],\n",
       "  [2, ['Kpoe', 'Farm house'], 34, 34],\n",
       "  [2, ['Lavulei', 'Sling used for scaring birds'], 35, 35],\n",
       "  [2, ['Mbahul', 'Seed rice'], 36, 36],\n",
       "  [2, ['Mbowei', 'Knife'], 37, 37],\n",
       "  [2, ['Mbale bowei rice', 'Sickle/knife used for cutting rice'], 38, 36]],\n",
       " 8: [[2, ['Mbogbeili', 'Cutlass'], 41, 41],\n",
       "  [2, ['Ps bogbel', 'Cutlass for cutting down trees'], 42, 41],\n",
       "  [2, ['Ndogboi', 'Bush'], 43, 43],\n",
       "  [2, ['Ndoli', 'Hook'], 44, 44],\n",
       "  [2, ['Ngombui', 'Fire'], 45, 45],\n",
       "  [2, ['Piyei', 'Container for putting'], 46, 46]],\n",
       " 10: [[2, ['Hosted for free on livelingua.com', 'â€˜'], 49, 49]]}"
      ]
     },
     "execution_count": 1304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Delete headers and such\n",
    "\"\"\"\n",
    "def sortShorties(data):\n",
    "    for i in data:\n",
    "        data[i] = list(itertools.filterfalse(lambda item: item[0] == 1 and item[1][0][0].isupper(), data[i]))\n",
    "\n",
    "sortShorties(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "lootoo waa gblagblaga cluster them together wa. ma bi na Ilo ('en', 0.32949830360373117)\n",
      "['Ke nya sina wama ngi mbei hinma, ba ti', \"Then E'll be coming tomorrow to kpeteihun lo. Biya see the swamp. When trans planting the rice, do not lootoo waa gblagblaga cluster them together\"] [('eo', 0.19990727066204522), ('en', 0.7047882144269162)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "climbing palm trees ('en', 0.8559684845370198)\n",
      "['Kpakai typical of Mendes especially an farms', 'Three legged wooden chair used especially an farms'] [('en', 0.8564262408245333), ('en', 0.8442687941393312)]\n",
      "\n",
      "\n",
      "\n",
      "2 0 0\n",
      "7 0 0\n",
      "7 0 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(1,\n",
       "   -1,\n",
       "   1,\n",
       "   \"Then E'll be coming tomorrow to kpeteihun lo. Biya see the swamp. When trans planting the rice, do not lootoo waa gblagblaga cluster them together lootoo waa gblagblaga cluster them together wa. ma bi na Ilo\"),\n",
       "  (6,\n",
       "   -1,\n",
       "   0,\n",
       "   'Kpakai typical of Mendes especially an farms climbing palm trees'),\n",
       "  (6,\n",
       "   -1,\n",
       "   1,\n",
       "   'Three legged wooden chair used especially an farms climbing palm trees')],\n",
       " [(2, 0, 0), (7, 0, 0), (7, 0, 0)])"
      ]
     },
     "execution_count": 1306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function attempts to designate lines that are continuations of the previous line.\n",
    "\"\"\"\n",
    "def matchStrayLines(data):\n",
    "    replacements = []\n",
    "    deletions = []\n",
    "    previous_para_id = int()\n",
    "    for i in data:\n",
    "        for line_idx, c in enumerate(data[i]):\n",
    "            if c[0] == 1 and c[1][0][0].islower():\n",
    "                in_phrases_idx = 0\n",
    "                current_phrase = c[1][0]\n",
    "                try:\n",
    "                    source_list = model.predict_proba_single(c[1][0].lower())[0]\n",
    "                except:\n",
    "                    source_list = ('nothin', 0)\n",
    "                if line_idx == 0:\n",
    "                    previous_phrases = data[previous_para_id][-1][1]\n",
    "                    try:\n",
    "                        target_list = [model.predict_proba_single(y.lower())[0] for y in previous_phrases]\n",
    "                    except:\n",
    "                        continue\n",
    "                    print(current_phrase, source_list)\n",
    "                    print(previous_phrases, target_list)\n",
    "                    addon = str()\n",
    "                    largestlength = 0\n",
    "                    try:\n",
    "                        prev_word = return_column(c[1][0])\n",
    "                        column_num = int()\n",
    "                        for index, phrase in enumerate(previous_phrases):\n",
    "                            if prev_word in phrase:\n",
    "                                column_num = index\n",
    "                        print(column_num)\n",
    "                        replacement_phrase = previous_phrases[column_num] + ' ' + current_phrase\n",
    "                        replacements.append((previous_para_id, -1, column_num, replacement_phrase))\n",
    "                        deletions.append((i, 0, 0))\n",
    "                        in_phrases_idx += 1\n",
    "                    except:\n",
    "                        for phrase, FTOutTup in zip(previous_phrases, target_list):\n",
    "                            if (source_list[0] == 'en' and FTOutTup[0] == 'en') or (source_list[0] != 'en' and FTOutTup[0] != 'en'):\n",
    "                                replacement_phrase = phrase + ' ' + current_phrase\n",
    "                                replacements.append((previous_para_id, -1, in_phrases_idx, replacement_phrase))\n",
    "                                deletions.append((i, 0, 0))\n",
    "                            in_phrases_idx += 1                           \n",
    "                else:\n",
    "                    previous_phrases = data[i][line_idx-1][1]\n",
    "                    try:\n",
    "                        target_list = [model.predict_proba_single(y.lower())[0] for y in previous_phrases]\n",
    "                    except:\n",
    "                        continue\n",
    "                    addon = str()\n",
    "                    try:\n",
    "                        prev_word = return_column(c[1][0])\n",
    "                        column_num = int()\n",
    "                        for index, phrase in enumerate(previous_phrases):\n",
    "                            if prev_word in phrase:\n",
    "                                column_num = index\n",
    "                        replacement_phrase = previous_phrases[column_num] + ' ' + current_phrase\n",
    "                        replacements.append((previous_para_id, -1, column_num, replacement_phrase))\n",
    "                        deletions.append((i, 0, 0))\n",
    "                        in_phrases_idx += 1\n",
    "                    except:\n",
    "                        for phrase, FTOutTup in zip(previous_phrases, target_list):\n",
    "                            if source_list[0] == 'en' and FTOutTup[0] == 'en':\n",
    "                                replacement_phrase = phrase + ' ' + current_phrase\n",
    "                                replacements.append((i, line_idx-1, in_phrases_idx, replacement_phrase))\n",
    "                                deletions.append((i, line_idx, 0))\n",
    "                            in_phrases_idx += 1\n",
    "        print('')\n",
    "        previous_para_id = i\n",
    "    for replacement in replacements:\n",
    "        pi, li, phri, phrase = replacement[0], replacement[1], replacement[2], replacement[3]\n",
    "        data[pi][li][1][phri] = phrase\n",
    "    for deletion in deletions:\n",
    "        pi, li, phri = deletion[0], deletion[1], deletion[2]\n",
    "        print(pi, li, phri)\n",
    "        try:\n",
    "            del data[pi][li]\n",
    "        except:\n",
    "            print('already deleted')\n",
    "    return replacements, deletions\n",
    "        \n",
    "matchStrayLines(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[2,\n",
       "   ['Bi nja we leila plo tisiea ti luahun',\n",
       "    'Did you make drainages in~-be tween the plots'],\n",
       "   1,\n",
       "   1]],\n",
       " 1: [[2,\n",
       "   ['Ke nya sina wama ngi mbei hinma, ba ti',\n",
       "    \"Then E'll be coming tomorrow to kpeteihun lo. Biya see the swamp. When trans planting the rice, do not lootoo waa gblagblaga cluster them together lootoo waa gblagblaga cluster them together wa. ma bi na Ilo\"],\n",
       "   5,\n",
       "   1]],\n",
       " 2: [],\n",
       " 4: [[2, ['Ke ba nya malelo', 'Then you will meet me'], 12, 1],\n",
       "  [2, ['Mua lo', 'We shall see'], 13, 1]],\n",
       " 5: [[2, ['Benbei', 'Fishing net'], 15, 15],\n",
       "  [2, ['Bumbui', 'Fishing Trap'], 16, 16],\n",
       "  [2, ['Due', 'Brush'], 17, 17],\n",
       "  [2, ['Due kpe', 'Brushing time'], 18, 17],\n",
       "  [2, ['Felei', 'Winnowing time'], 19, 19],\n",
       "  [2, ['Gaaga kpe', 'Time for clearing after burning'], 20, 1],\n",
       "  [2, ['Hambui', 'An object made of wire hung over'], 21, 21]],\n",
       " 6: [[1, ['fire for drying fish or meat'], 22, 1],\n",
       "  [2, ['Kali', 'Hoe'], 22, 22],\n",
       "  [2, ['Kondei', 'Mortar'], 23, 23],\n",
       "  [2, ['Koni', 'Axe'], 24, 24],\n",
       "  [2, ['Kobot', 'Mat (made out cf bamboo'], 25, 25],\n",
       "  [2,\n",
       "   ['Kpakai typical of Mendes especially an farms climbing palm trees',\n",
       "    'Three legged wooden chair used especially an farms climbing palm trees'],\n",
       "   26,\n",
       "   1]],\n",
       " 7: [[2, ['Kpuloi', 'Gourd/keg'], 33, 33],\n",
       "  [2, ['Kpoe', 'Farm house'], 34, 34],\n",
       "  [2, ['Lavulei', 'Sling used for scaring birds'], 35, 35],\n",
       "  [2, ['Mbahul', 'Seed rice'], 36, 36],\n",
       "  [2, ['Mbowei', 'Knife'], 37, 37],\n",
       "  [2, ['Mbale bowei rice', 'Sickle/knife used for cutting rice'], 38, 36]],\n",
       " 8: [[2, ['Mbogbeili', 'Cutlass'], 41, 41],\n",
       "  [2, ['Ps bogbel', 'Cutlass for cutting down trees'], 42, 41],\n",
       "  [2, ['Ndogboi', 'Bush'], 43, 43],\n",
       "  [2, ['Ndoli', 'Hook'], 44, 44],\n",
       "  [2, ['Ngombui', 'Fire'], 45, 45],\n",
       "  [2, ['Piyei', 'Container for putting'], 46, 46]],\n",
       " 10: [[2, ['Hosted for free on livelingua.com', 'â€˜'], 49, 49]]}"
      ]
     },
     "execution_count": 1307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "already replaced\n",
      "set()\n",
      "\n",
      "data\n",
      "0\n",
      "\t 0 \t [2, ['Bi nja we leila plo tisiea ti luahun', 'Did you make drainages in~-be tween the plots'], 1, 1]\n",
      "1\n",
      "\t 0 \t [2, ['Ke nya sina wama ngi mbei hinma, ba ti', \"Then E'll be coming tomorrow to kpeteihun lo. Biya see the swamp. When trans planting the rice, do not lootoo waa gblagblaga cluster them together lootoo waa gblagblaga cluster them together wa. ma bi na Ilo\"], 5, 1]\n",
      "2\n",
      "4\n",
      "\t 0 \t [2, ['Ke ba nya malelo', 'Then you will meet me'], 12, 1]\n",
      "\t 1 \t [2, ['Mua lo', 'We shall see'], 13, 1]\n",
      "5\n",
      "\t 0 \t [2, ['Benbei', 'Fishing net'], 15, 15]\n",
      "\t 1 \t [2, ['Bumbui', 'Fishing Trap'], 16, 16]\n",
      "\t 2 \t [2, ['Due', 'Brush'], 17, 17]\n",
      "\t 3 \t [2, ['Due kpe', 'Brushing time'], 18, 17]\n",
      "\t 4 \t [2, ['Felei', 'Winnowing time'], 19, 19]\n",
      "\t 5 \t [2, ['Gaaga kpe', 'Time for clearing after burning'], 20, 1]\n",
      "\t 6 \t [2, ['Hambui', 'An object made of wire hung over'], 21, 21]\n",
      "6\n",
      "\t 0 \t [1, ['fire for drying fish or meat'], 22, 1]\n",
      "\t 1 \t [2, ['Kali', 'Hoe'], 22, 22]\n",
      "\t 2 \t [2, ['Kondei', 'Mortar'], 23, 23]\n",
      "\t 3 \t [2, ['Koni', 'Axe'], 24, 24]\n",
      "\t 4 \t [2, ['Kobot', 'Mat (made out cf bamboo'], 25, 25]\n",
      "\t 5 \t [2, ['Kpakai typical of Mendes especially an farms climbing palm trees', 'Three legged wooden chair used especially an farms climbing palm trees'], 26, 1]\n",
      "7\n",
      "\t 0 \t [2, ['Kpuloi', 'Gourd/keg'], 33, 33]\n",
      "\t 1 \t [2, ['Kpoe', 'Farm house'], 34, 34]\n",
      "\t 2 \t [2, ['Lavulei', 'Sling used for scaring birds'], 35, 35]\n",
      "\t 3 \t [2, ['Mbahul', 'Seed rice'], 36, 36]\n",
      "\t 4 \t [2, ['Mbowei', 'Knife'], 37, 37]\n",
      "\t 5 \t [2, ['Mbale bowei rice', 'Sickle/knife used for cutting rice'], 38, 36]\n",
      "8\n",
      "\t 0 \t [2, ['Mbogbeili', 'Cutlass'], 41, 41]\n",
      "\t 1 \t [2, ['Ps bogbel', 'Cutlass for cutting down trees'], 42, 41]\n",
      "\t 2 \t [2, ['Ndogboi', 'Bush'], 43, 43]\n",
      "\t 3 \t [2, ['Ndoli', 'Hook'], 44, 44]\n",
      "\t 4 \t [2, ['Ngombui', 'Fire'], 45, 45]\n",
      "\t 5 \t [2, ['Piyei', 'Container for putting'], 46, 46]\n",
      "10\n",
      "\t 0 \t [2, ['Hosted for free on livelingua.com', 'â€˜'], 49, 49]\n",
      "\n",
      "replacements\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], <list_reverseiterator at 0x7f5e114f86d8>)"
      ]
     },
     "execution_count": 1308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matchStrayLines2(data):\n",
    "    replacements = []\n",
    "    deletions = []\n",
    "    previous_para_id = int()\n",
    "    collapse_marker = False\n",
    "    for i in data:\n",
    "        for line_idx, c in enumerate(data[i]):\n",
    "            try:\n",
    "                if len(c[1]) == 2 and (c[1][0][0].islower() or c[1][1][0].islower()) and len(data[previous_para_id][-1][1]) == 2:\n",
    "                    in_phrases_idx = 0\n",
    "                    first_phrase = c[1][0]\n",
    "                    second_phrase = c[1][1]\n",
    "                    if line_idx == 0:\n",
    "                        previous_phrases = data[previous_para_id][-1][1]\n",
    "                        addon = str()\n",
    "                        for prev_phrase, add_phrase in zip(previous_phrases, c[1]):\n",
    "                            replacement_phrase = add_phrase\n",
    "                            replacements.append([previous_para_id, -1, in_phrases_idx, replacement_phrase])\n",
    "                            deletions.append((i, 0))\n",
    "                            in_phrases_idx += 1\n",
    "                    else:\n",
    "                        previous_phrases = data[i][line_idx-1][1]\n",
    "                        addon = str()\n",
    "                        for prev_phrase, add_phrase in zip(previous_phrases, c[1]):\n",
    "                            #print(\"prev: \", prev_phrase)\n",
    "                            #print(\"add: \",add_phrase)\n",
    "                            replacement_phrase = add_phrase\n",
    "                            replacements.append([i, line_idx-1, in_phrases_idx, replacement_phrase])\n",
    "                            deletions.append((i, line_idx))\n",
    "                            #print([i, line_idx-1, in_phrases_idx, replacement_phrase])\n",
    "                            #print('')\n",
    "                            in_phrases_idx += 1\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "                #print('')\n",
    "        previous_para_id = i\n",
    "    \n",
    "    replacements = list(reversed(replacements))\n",
    "    print(replacements)\n",
    "    already_replaced = set()\n",
    "    for repl_id, replacement in enumerate(replacements):\n",
    "        pi, li, phri, phrase = replacement[0], replacement[1], replacement[2], replacement[3]\n",
    "        try:\n",
    "            pi_prev, li_prev, phri_prev, phrase_prev = replacements[repl_id+2][0], replacements[repl_id+2][1], replacements[repl_id+2][2], replacements[repl_id+2][3]\n",
    "            if pi == pi_prev and li == li_prev+1 and phri == phri_prev:\n",
    "                data[pi][li][1][phri] = data[pi][li][1][phri] + ' ' + phrase\n",
    "                replacements[repl_id+2][3] = data[pi][li][1][phri]\n",
    "                #already_replaced.add((pi_prev, li_prev, phri_prev))\n",
    "            else:\n",
    "                print(\"else: \" + data[pi][li][1][phri] + ' ' + phrase)\n",
    "                if (pi, li, phri) not in already_replaced:\n",
    "                    print(\"yeah: \" + data[pi][li][1][phri] + ' ' + phrase)\n",
    "                    data[pi][li][1][phri] = data[pi][li][1][phri] + ' ' + phrase\n",
    "        except:\n",
    "            print(data[pi][li][1][phri] + ' ' + phrase)\n",
    "            data[pi][li][1][phri] = data[pi][li][1][phri] + ' ' + phrase\n",
    "            print('list index out of range')\n",
    "    \n",
    "    print('already replaced')\n",
    "    print(already_replaced)\n",
    "    print('')\n",
    "    print(\"data\")\n",
    "    for h in data:\n",
    "        print(h)\n",
    "        for index, j in enumerate(data[h]):\n",
    "            print(\"\\t\", index, \"\\t\", j)\n",
    "    print('')\n",
    "    print('replacements')\n",
    "    print(replacements)\n",
    "    \n",
    "    deletions = reversed(list(OrderedDict.fromkeys(deletions)))\n",
    "    for deletion in deletions:\n",
    "        pi, li = deletion[0], deletion[1]\n",
    "        print(pi, li, phri)\n",
    "        try:\n",
    "            del data[pi][li]\n",
    "        except:\n",
    "            print('already deleted')\n",
    "    return replacements, deletions\n",
    "    \n",
    "\n",
    "        \n",
    "matchStrayLines2(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteBlanks(data):\n",
    "    for k, v in list(data.items()):\n",
    "        if v == []:\n",
    "            del data[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[2,\n",
       "   ['Bi nja we leila plo tisiea ti luahun',\n",
       "    'Did you make drainages in~-be tween the plots'],\n",
       "   1,\n",
       "   1]],\n",
       " 1: [[2,\n",
       "   ['Ke nya sina wama ngi mbei hinma, ba ti',\n",
       "    \"Then E'll be coming tomorrow to kpeteihun lo. Biya see the swamp. When trans planting the rice, do not lootoo waa gblagblaga cluster them together lootoo waa gblagblaga cluster them together wa. ma bi na Ilo\"],\n",
       "   5,\n",
       "   1]],\n",
       " 2: [],\n",
       " 4: [[2, ['Ke ba nya malelo', 'Then you will meet me'], 12, 1],\n",
       "  [2, ['Mua lo', 'We shall see'], 13, 1]],\n",
       " 5: [[2, ['Benbei', 'Fishing net'], 15, 15],\n",
       "  [2, ['Bumbui', 'Fishing Trap'], 16, 16],\n",
       "  [2, ['Due', 'Brush'], 17, 17],\n",
       "  [2, ['Due kpe', 'Brushing time'], 18, 17],\n",
       "  [2, ['Felei', 'Winnowing time'], 19, 19],\n",
       "  [2, ['Gaaga kpe', 'Time for clearing after burning'], 20, 1],\n",
       "  [2, ['Hambui', 'An object made of wire hung over'], 21, 21]],\n",
       " 6: [[1, ['fire for drying fish or meat'], 22, 1],\n",
       "  [2, ['Kali', 'Hoe'], 22, 22],\n",
       "  [2, ['Kondei', 'Mortar'], 23, 23],\n",
       "  [2, ['Koni', 'Axe'], 24, 24],\n",
       "  [2, ['Kobot', 'Mat (made out cf bamboo'], 25, 25],\n",
       "  [2,\n",
       "   ['Kpakai typical of Mendes especially an farms climbing palm trees',\n",
       "    'Three legged wooden chair used especially an farms climbing palm trees'],\n",
       "   26,\n",
       "   1]],\n",
       " 7: [[2, ['Kpuloi', 'Gourd/keg'], 33, 33],\n",
       "  [2, ['Kpoe', 'Farm house'], 34, 34],\n",
       "  [2, ['Lavulei', 'Sling used for scaring birds'], 35, 35],\n",
       "  [2, ['Mbahul', 'Seed rice'], 36, 36],\n",
       "  [2, ['Mbowei', 'Knife'], 37, 37],\n",
       "  [2, ['Mbale bowei rice', 'Sickle/knife used for cutting rice'], 38, 36]],\n",
       " 8: [[2, ['Mbogbeili', 'Cutlass'], 41, 41],\n",
       "  [2, ['Ps bogbel', 'Cutlass for cutting down trees'], 42, 41],\n",
       "  [2, ['Ndogboi', 'Bush'], 43, 43],\n",
       "  [2, ['Ndoli', 'Hook'], 44, 44],\n",
       "  [2, ['Ngombui', 'Fire'], 45, 45],\n",
       "  [2, ['Piyei', 'Container for putting'], 46, 46]],\n",
       " 10: [[2, ['Hosted for free on livelingua.com', 'â€˜'], 49, 49]]}"
      ]
     },
     "execution_count": 1310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteBlanks(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Ke ba nya malelo\n",
      "1 Then you will meet me\n",
      "2 ['Ke ba nya malelo', 'Then you will meet me']\n",
      "0 Mua lo\n",
      "1 We shall see\n",
      "2 ['Mua lo', 'We shall see']\n",
      "\n",
      "Here are the columns\n",
      "[['Ke ba nya malelo', 'Mua lo'], ['Then you will meet me', 'We shall see']]\n",
      "the leng 2\n",
      "{0: 'es', 1: 'en'}\n",
      "2\n",
      "0\n",
      "es en\n",
      "0 Ke ba nya malelo Then you will meet me\n",
      "0 Mua lo We shall see\n",
      "game cancelled\n"
     ]
    }
   ],
   "source": [
    "columns = []\n",
    "if content[4] != []:\n",
    "    mode = modedict[4]\n",
    "    for x in content[4]:\n",
    "        linenum = x[0]\n",
    "        splits = x[1]\n",
    "        if linenum % 2 == 0:\n",
    "            for idx, split in enumerate(splits):\n",
    "                try:\n",
    "                    columns[idx].append(split)\n",
    "                    print(idx, split)\n",
    "                except:\n",
    "                    columns.append([])\n",
    "                    columns[idx].append(split)\n",
    "                    print(idx, split)\n",
    "            print(linenum, splits)\n",
    "        else:\n",
    "            pass\n",
    "    print('')\n",
    "    print('Here are the columns')\n",
    "    try:\n",
    "        it = iter(columns)\n",
    "        print(columns)\n",
    "        the_len = len(columns[0])\n",
    "        print('the leng', the_len)\n",
    "        column_lang = {}\n",
    "\n",
    "        for col_i, column in enumerate(columns):\n",
    "            proc_col = [''.join(x.lower().split('/')) for x in column]\n",
    "            FTout = model.predict_proba_single(\" \".join(proc_col), k=1)\n",
    "            try:\n",
    "                tuple = FTout[0]\n",
    "                column_lang[col_i] = tuple[0]\n",
    "                if tuple[0] == 'en' and tuple[1] < .35:\n",
    "                    column_lang[col_i] = 'nothin'\n",
    "            except:\n",
    "                column_lang[col_i] = 'nothin'\n",
    "        column_index = 0\n",
    "        print(column_lang)\n",
    "        print(len(columns))\n",
    "        while column_index < len(columns):\n",
    "            try:\n",
    "                print(column_index)\n",
    "                print(column_lang[column_index], column_lang[column_index+1])\n",
    "                if column_lang[column_index] == 'en' and column_lang[column_index + 1] != 'en':\n",
    "                    for phrase1, phrase2 in zip(columns[column_index], columns[column_index+1]):\n",
    "                        dictionary[phrase1] = phrase2\n",
    "                        print(column_index, phrase1, phrase2)\n",
    "                    column_index += 2\n",
    "                elif column_lang[column_index] != 'en' and column_lang[column_index + 1] == 'en':\n",
    "                    for phrase1, phrase2 in zip(columns[column_index], columns[column_index+1]):\n",
    "                        dictionary[phrase2] = phrase1\n",
    "                        print(column_index, phrase1, phrase2)\n",
    "                    column_index += 2\n",
    "                else:\n",
    "                    column_index += 2\n",
    "            except:\n",
    "                break\n",
    "        else:\n",
    "            print('game cancelled')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then you will meet me \t \t Ke ba nya malelo\n",
      "We shall see \t \t Mua lo\n"
     ]
    }
   ],
   "source": [
    "for i in dictionary:\n",
    "    print(i, '\\t', '\\t', dictionary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the leng 1\n",
      "0 Bi nja we leila plo tisiea ti luahun Did you make drainages in~-be tween the plots\n",
      "\n",
      "the leng 1\n",
      "0 Ke nya sina wama ngi mbei hinma, ba ti Then E'll be coming tomorrow to kpeteihun lo. Biya see the swamp. When trans planting the rice, do not lootoo waa gblagblaga cluster them together\n",
      "\n",
      "the leng 1\n",
      "\n",
      "the leng 2\n",
      "0 Ke ba nya malelo Then you will meet me\n",
      "0 Mua lo We shall see\n",
      "\n",
      "the leng 7\n",
      "\n",
      "the leng 6\n",
      "\n",
      "the leng 8\n",
      "\n",
      "the leng 6\n",
      "0 Mbogbeili Cutlass\n",
      "0 Ps bogbel Cutlass for cutting down trees\n",
      "0 Ndogboi Bush\n",
      "0 Ndoli Hook\n",
      "0 Ngombui Fire\n",
      "0 Piyei Container for putting\n",
      "\n",
      "the leng 1\n",
      "Did you make drainages in~-be tween the plots \t \t Bi nja we leila plo tisiea ti luahun\n",
      "Then E'll be coming tomorrow to kpeteihun lo. Biya see the swamp. When trans planting the rice, do not lootoo waa gblagblaga cluster them together \t \t Ke nya sina wama ngi mbei hinma, ba ti\n",
      "Then you will meet me \t \t Ke ba nya malelo\n",
      "We shall see \t \t Mua lo\n",
      "Cutlass \t \t Mbogbeili\n",
      "Cutlass for cutting down trees \t \t Ps bogbel\n",
      "Bush \t \t Ndogboi\n",
      "Hook \t \t Ndoli\n",
      "Fire \t \t Ngombui\n",
      "Container for putting \t \t Piyei\n"
     ]
    }
   ],
   "source": [
    "modedict = getModeSplits(content)\n",
    "for i in content:\n",
    "    columns = []\n",
    "    if content[i] != []:\n",
    "        for x in content[i]:\n",
    "            linenum = x[0]\n",
    "            splits = x[1]\n",
    "            for idx, split in enumerate(splits):\n",
    "                try:\n",
    "                    columns[idx].append(split)\n",
    "                except:\n",
    "                    columns.append([])\n",
    "                    columns[idx].append(split)\n",
    "            #print(linenum, splits)\n",
    "        print('')\n",
    "        it = iter(columns)\n",
    "        the_len = len(columns[0])\n",
    "        print('the leng', the_len)\n",
    "        #if all(len(x) == the_len for x in columns):\n",
    "        column_lang = {}\n",
    "        for col_i, column in enumerate(columns):\n",
    "            proc_col = [''.join(x.split('/')) for x in column]\n",
    "            FTout = model.predict_proba_single(\" \".join(proc_col), k=1)\n",
    "            try:\n",
    "                tuple = FTout[0]\n",
    "                column_lang[col_i] = tuple[0]\n",
    "                if tuple[0] == 'en' and tuple[1] < .35:\n",
    "                    column_lang[col_i] = 'nothin'\n",
    "            except:\n",
    "                column_lang[col_i] = 'nothin'\n",
    "        column_index = 0\n",
    "        while column_index < len(columns):\n",
    "            try:\n",
    "                if column_lang[column_index] == 'en' and column_lang[column_index + 1] != 'en':\n",
    "                    for phrase1, phrase2 in zip(columns[column_index], columns[column_index+1]):\n",
    "                        dictionary[phrase1] = phrase2\n",
    "                        print(column_index, phrase1, phrase2)\n",
    "                    column_index += 2\n",
    "                elif column_lang[column_index] != 'en' and column_lang[column_index + 1] == 'en':\n",
    "                    for phrase1, phrase2 in zip(columns[column_index], columns[column_index+1]):\n",
    "                        dictionary[phrase2] = phrase1\n",
    "                        print(column_index, phrase1, phrase2)\n",
    "                    column_index += 2\n",
    "                else:\n",
    "                    column_index += 2\n",
    "            except:\n",
    "                break\n",
    "for i in dictionary:\n",
    "    print(i, '\\t', '\\t', dictionary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Did you make drainages in~-be tween the plots': 'Bi nja we leila plo tisiea ti luahun',\n",
       " \"Then E'll be coming tomorrow to kpeteihun lo. Biya see the swamp. When trans planting the rice, do not lootoo waa gblagblaga cluster them together\": 'Ke nya sina wama ngi mbei hinma, ba ti',\n",
       " 'Then you will meet me': 'Ke ba nya malelo',\n",
       " 'We shall see': 'Mua lo',\n",
       " 'Cutlass': 'Mbogbeili',\n",
       " 'Cutlass for cutting down trees': 'Ps bogbel',\n",
       " 'Bush': 'Ndogboi',\n",
       " 'Hook': 'Ndoli',\n",
       " 'Fire': 'Ngombui',\n",
       " 'Container for putting': 'Piyei'}"
      ]
     },
     "execution_count": 1268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
